from talon import Context, Module, actions
ctx = Context()
ctx.matches = '\napp: intelij\n'
mod = Module()
python_keywords = {'false': 'False', 'none': 'None', 'true': 'True', 'and': 'and', 'as': 'as', 'assert': 'assert', 'async': 'async', 'await': 'await', 'break': 'break', 'class': 'class', 'continue': 'continue', 'define': 'def', 'elif': 'elif', 'else': 'else', 'except': 'except', 'finally': 'finally', 'for': 'for', 'from': 'from', 'global': 'global', 'if': 'if', 'import': 'import', 'in': 'in', 'is': 'is', 'lambda': 'lambda', 'nonlocal': 'nonlocal', 'not': 'not', 'or': 'or', 'pass': 'pass', 'raise': 'raise', 'return': 'return', 'try': 'try', 'while': 'while', 'with': 'with', 'yield': 'yield', 'telephone': 'THIS IS TEST'}
mod.list('vocabulary', desc='additional vocabulary words')
automatically_generated_mapping = {'import': 'import', 'asyncio': 'asyncio', 'collections': 'collections', 'namedtuple': 'namedtuple', 'beanie': 'beanie', 'exceptions': '.exceptions', 'revisionidwaschanged': 'RevisionIdWasChanged', 'dataclasses': 'dataclasses', 'dataclass': 'dataclass', 'logging': 'logging', 'numpy': 'numpy', 'rapidfuzz': 'rapidfuzz', 'textdistance': 'textdistance', 'operators': '.operators', 'comparison': '.comparison', 'pymongo': 'pymongo', 'errors': '.errors', 'duplicatekeyerror': 'DuplicateKeyError', 'typing': 'typing', 'iterable': 'Iterable', 'sequence': 'Sequence', 'fastapi': 'fastapi', 'httpexception': 'HTTPException', 'rest api': '.rest_api', 'rest': 'rest', 'constants': '.Constants', 'global': 'global', 'global project': 'GLOBAL_PROJECT_', 'global project id': 'GLOBAL_PROJECT_ID', 'projectid': 'projectid', 'pagesize': 'pageSize', 'semantic': 'semantic', 'semantic search': 'SEMANTIC_SEARCH_', 'semantic search embedding': 'SEMANTIC_SEARCH_EMBEDDING_', 'semantic search embedding version': 'SEMANTIC_SEARCH_EMBEDDING_VERSION', 'word tokenizer': 'word_tokenizer', 'word': 'word', 'response': 'response', 'response models': '.response_models', 'searchentry': 'SearchEntry', 'indexkey': '.indexKey', 'searchresponse': 'SearchResponse', 'indexedsemanticsearchentry': 'IndexedSemanticSearchEntry', 'indexedsearchentry': 'IndexedSearchEntry', 'referenceid': '.referenceId', 'searchstrategy': 'SearchStrategy', 'async': 'async', 'check': 'check', 'check all': 'check_all_', 'check all entries': 'check_all_entries_', 'check all entries for': 'check_all_entries_for_', 'check all entries for indexing': 'check_all_entries_for_indexing_', 'synchronousembeddingprocessor': 'synchronousEmbeddingProcessor', 'itertools': 'itertools', 'groupby': 'groupby', 'outdated': 'outdated', 'outdated entries': 'outdated_entries', 'semanticsearch': '.semanticSearch', 'version': '.version', 'await': 'await', 'to list': '.to_list', 'to': 'to', 'sorted': 'sorted', 'lambda': 'lambda', 'language': '.language', 'groups': 'groups', 'futures': 'futures', 'search': 'search', 'search entries': 'search_entries', 'fromindexedsearchentry': '.fromIndexedSearchEntry', 'entry': 'entry', 'fromsearchentries': '.fromSearchEntries', 'semantic entry': 'semantic_entry', 'append': '.append', 'gather': '.gather', 'savesearchentries': 'saveSearchEntries', 'searchentries': 'searchEntries', 'project': 'project', 'project id': 'project_id', 'indexedsearchentries': 'indexedSearchEntries', 'existing': 'existing', 'existing document': 'existing_document', 'find one': '.find_one', 'find': 'find', 'update': 'update', 'update entry': '.update_entry', 'return': 'return', 'checkifprojectexists': 'checkIfProjectExists', 'results': 'results', 'raise': 'raise', 'status': 'status', 'status code': 'status_code', 'detail': 'detail', 'listindices': 'listIndices', 'result': 'result', 'aggregate': '.aggregate', 'index': '.index', 'bestmatchsearch': 'bestMatchSearch', 'searchkey': 'searchKey', 'number': 'number', 'number of': 'number_of_', 'number of results': 'number_of_results', 'exactsearch': 'exactSearch', 'fuzzysearch': 'fuzzySearch', 'score': 'score', 'start': 'start', 'searchresult': 'SearchResult', 'fuzzysearchmongeelkan': 'fuzzySearchMongeElkan', 'searchterm': 'searchTerm', 'content': 'content', 'searchkeytokens': 'searchKeyTokens', 'findall': '.findall', 'candidates': 'candidates', 'process': '.process', 'extract': 'extract', 'extract iter': '.extract_iter', 'scorer': 'scorer', 'partial': 'partial', 'partial ratio': '.partial_ratio', 'score cutoff': 'score_cutoff', 'candidate': 'candidate', 'candidate split': 'candidate_split', 'ngrams': 'ngrams', 'range': 'range', 'ratio': '.ratio', 'chunk': 'chunk', 'replace': '.replace', 'match': 'match', 'dotall': '.DOTALL', 'reverse': 'reverse', 'relevantentries': 'relevantEntries', 'fetch': 'fetch', 'fetch links': 'fetch_links', 'relevant': 'relevant', 'relevant content': 'relevant_content', 'contentvalue': '.contentValue', 'fuzzy': 'fuzzy', 'fuzzy scores': 'fuzzy_scores', 'search strategy': 'search_strategy', 'similarity': 'similarity', 'start offset': 'start_offset', 'end offset': 'end_offset', 'end': 'end', 'offsets': 'offsets', 'exact': '.exact', 'getrowfromsimilaritymatrix': 'getRowFromSimilarityMatrix', 'referenceentry': 'referenceEntry', 'referenceembedding': 'referenceEmbedding', 'array': '.array', 'embedding': '.embedding', 'similarities': 'similarities', 'entryembedding': 'entryEmbedding', 'linalg': '.linalg', 'metadata': '.metaData', 'asynchronousembeddingprocessor': 'asynchronousEmbeddingProcessor', 'processor': 'processor', 'asynchronousprocess': 'asynchronousProcess', 'split': '.split', 'false': 'False', 'searchembedding': 'searchEmbedding', 'getembedding': '.getEmbedding', 'flatten': '.flatten', 'asynchronous': 'asynchronous', 'asynchronous embedding': '.asynchronous_embedding', 'generic': 'generic', 'generic delete': 'generic_delete_', 'generic delete method': 'generic_delete_method', 'list of': 'list_of_', 'list': 'list', 'list of raat': 'list_of_raat_', 'list of raat ids': 'list_of_raat_ids', 'entries': 'entries', 'entries to': 'entries_to_', 'entries to be': 'entries_to_be_', 'entries to be deleted': 'entries_to_be_deleted', 'deleted': 'deleted', 'deleted reference': 'deleted_reference_', 'deleted reference id': 'deleted_reference_id', 'delete': '.delete'}
mod.list('python_keywords', desc='Automatically extracted key words from python files')
ctx.lists['self.python_keywords'] = dict(automatically_generated_mapping, **python_keywords)
ctx.lists['user.vocabulary'] = dict(automatically_generated_mapping, **python_keywords)

@mod.capture(rule='{self.python_keywords}+')
def python_keywords(m) -> str:
    return ''.join(m.python_keywords_list)